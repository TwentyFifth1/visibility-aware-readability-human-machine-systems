# Visibility-Aware Readability (Human–Machine Systems)

This repository contains reproducible, publication-grade materials for studying text readability feasibility under controlled, classroom-like viewing configurations. The work is situated within the domain of human–machine systems, with a deliberate emphasis on perceptual accessibility rather than user intent, cognition, or downstream behavioral outcomes.

This repository is created as an **individual submission** for the Human–Machine Systems course (Week 17: Implementation & GitHub Deployment). The scientific formulation, experimental design, implementation, and reported results follow the group project repository referenced below.

---

## Background and Motivation

Readability is often treated as a downstream cognitive or behavioral outcome. However, before comprehension, attention, or task performance can be meaningfully discussed, text must first be perceptually readable in principle.

In classroom-like environments, readability depends on a combination of geometric factors (e.g., viewing distance and angular size), perceptual factors (e.g., contrast and medium), and observer configuration (e.g., head pose). This project focuses on modeling this perceptual feasibility layer and examining whether a human-rated visibility score can serve as a predictively sufficient proxy for readability.

---

## Research Objective

The primary objective of this project is to model whether text is readable *in principle* (`can_read`) given a specific viewing configuration. In particular, the study investigates:

- Whether a human-rated visibility score alone is predictively sufficient
- How visibility compares against richer geometric and environmental feature sets
- How robust predictive performance is under distributional shift and perturbation

The emphasis is placed on interpretability, validation rigor, and uncertainty-aware evaluation rather than solely maximizing predictive accuracy.

---

## Reference Repository (Group Project)

The full group project repository, which contains all executable source code and experimental artifacts, is available at:

https://github.com/NattakittiP/visibility_aware_readability

All core scientific contributions, modeling decisions, and reported results originate from the group project repository above. This repository exists to satisfy the individual GitHub repository requirement.

---

## Scope and Interpretation (Important)

The dataset includes a human-rated visibility score that acts as a perceptual proxy for readability. Because this score is derived from human judgment, it is conceptually and statistically correlated with the binary readability label (`can_read`).

Accordingly, all analyses should be interpreted under the following constraints:

- Results reflect **predictive sufficiency**, not causal sufficiency
- Deployability in unconstrained real-world classrooms is not claimed
- The contribution is methodological rather than prescriptive
- Claims are restricted to the controlled measurement regime studied

---

## Repository Organization (Original Design)

The referenced repository is intentionally structured to support clean reproducibility, transparent auditing, and reviewer-friendly inspection. It is split into two primary branches:

### Code
Contains all executable source code used in the study, including data preprocessing, model training, evaluation pipelines, and analysis scripts. All pipelines are designed to be leakage-safe and methodologically consistent.

### Result
Contains all artifacts generated by the code, including CSV tables, figures, and LaTeX files corresponding exactly to the reported experimental results. This strict separation ensures that reported findings can be independently verified.

---

## Experimental Pipeline Overview

Running the code in the referenced repository reproduces the full experimental pipeline reported in the manuscript.

### Scenario-Level Evaluation
- Repeated stratified cross-validation
- Pooled out-of-fold (OOF) prediction aggregation
- Condition-blocked cross-validation to simulate deployment shift

### Modeling Approaches
- L2-regularized Logistic Regression
- Random Forest classifiers
- Unified preprocessing pipelines for fair comparison

### Probability Calibration
- Uncalibrated baselines
- Platt scaling
- Isotonic regression  
(All calibration models are fit strictly on training-only predictions.)

### Explainability and Diagnostics
- Impurity-based feature importance
- Permutation importance
- One- and two-dimensional Partial Dependence Plots (PDPs)

### Sufficiency-Oriented Analyses
- Geometry-only models
- Visibility-only models
- Geometry plus visibility models
- Paired AUC comparisons using pooled OOF predictions
- Residualization-style stress tests
- Information-theoretic summaries

### Robustness and Uncertainty-Aware Evaluation
- Structured perturbations and stress tests
- Bootstrap confidence intervals
- Subgroup and worst-case reporting
- Split conformal prediction
- Mondrian (group-conditional) conformal prediction coverage

---

## Dataset Assumptions
All scripts assume the presence of a CSV file named:


### Required Columns

**Target**
- `can_read` (binary)

**Visibility**
- `visibility_score`

**Geometry**
- `distance_m`
- `font_size_pt`
- `text_height_mm`
- `angular_size_deg`

**Head Pose**
- `head_yaw_deg`
- `head_pitch_deg`
- `head_roll_deg`

**Viewing Conditions**
- `medium`
- `contrast`

**Optional**
- `participant_id`

If `participant_id` is absent, some scripts generate balanced pseudo-participants strictly for stress-testing and LOPO-style evaluation. These pseudo-identifiers are not treated as real subjects.

---

## Installation

The codebase relies on standard scientific Python libraries and is designed to be lightweight and reproducible. A virtual environment is recommended.

### Requirements
- Python 3.8 or newer
- CPU-only execution

### Install Dependencies

```bash
pip install -U numpy pandas scikit-learn scipy matplotlib tqdm seaborn


